---
sidebar_position: 2
---

# Ollama

Ollama 是一款开源跨平台大语言模型（LLM）本地化部署工具，专注于简化 LLM 在本地环境中的运行、管理和推理流程。它支持用户通过简单命令在个人设备（如 PC、边缘服务器）上直接部署和调用预训练模型（如 LLaMA、DeepSeek 等），无需依赖云端服务或高性能 GPU。

## 安装

```shell
sudo apt update
sudo apt install spacemit-ollama-toolkit
```

验证：

```shell
ollama list
```

最后输出 `NAME  ID  SIZE  MODIFIED` 表示安装成功。

## 下载模型

因为q4_0的模型在k1开发板上才能发挥最好的性能，我们强烈推荐您下载q4_0的模型。在modelscope上选择想要下载的gguf类型模型，下载q4_0量化精度的模型到开发板或者musebook。

下方是模型制作的示例：

```shell
sudo apt install wget
wget https://modelscope.cn/models/second-state/Qwen2.5-0.5B-Instruct-GGUF/resolve/master/Qwen2.5-0.5B-Instruct-Q4_0.gguf ~/
wget https://archive.spacemit.com/spacemit-ai/modelfile/qwen2.5:0.5b.modelfile ~/
cd ~/
ollama create qwen2.5:0.5b -f qwen2.5:0.5b.modelfile
```

## 使用

```shell
ollama run qwen2.5:0.5b
```
